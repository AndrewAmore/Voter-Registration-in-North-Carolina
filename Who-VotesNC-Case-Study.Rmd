---
title: |
  | \vspace{-1.4cm} \textbf{Analyzing Voter Registration in the 2016 Presidential Election} \vspace{-0.5cm}
author: Andrew Amore 
date: |
  | \vspace{-0.6cm} \small 2022-11-21
output: 
  pdf_document:
    number_sections: true
urlcolor: blue
fontsize: 12pt
geometry: "left=2cm, right=2cm, top=1.25cm, bottom=1.25cm"
subparagraph: yes
header-includes: |
  \usepackage{titlesec}
  \titlespacing{\title}{0pt}{\parskip}{-\parskip}
  \titlespacing{\section}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
  \titlespacing{\subsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
  \titlespacing{\subsubsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
---

\vspace{-1.1cm}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include=FALSE, echo=FALSE, warning=FALSE, 
                      message=FALSE, fig.align = "center")

library(tidyverse)  # data manipulation
library(rstan)      # statistical modeling
library(brms)       # statistical modeling
library(ggmcmc)     # mcmc interpretation
library(ggthemes)   # mcmc interpretation
library(ggridges)   # mcmc interpretation
library(bayesplot)  # mcmc interpretation
library(tidybayes)  # mcmc interpretation
library(coda)       # mcmc interpretation
library(arm)
library(ggpubr)     # panel plotting
library(rcompanion) # for correlation computation with categorical variables
library(gridExtra)  # plot manipulation
library(pander)     # table presentation
source("utilities.R")

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

```{r, data-load-and-clean}
census = load_census_df()
voter_stats = load_voter_df()
```

# Introduction
Political campaigns analyze historical election data to understand how demographic
factors influence voter registration rates. This information can inform optimal 
advertising strategies which can drum up more votes and win elections, especially
during high profile presidential election years when voter turnout can be 
substantially higher. 

In this report, 2016 election data from North Carolina counties was used to 
investigate how geography, gender, age and party affiliation influence registration
behavior. Section 2 provides some background information on hierarchical modeling
and discusses some favorable properties attractive under the voter registration 
context. Section 3 reviews the data used in the analysis, highlights a challenge
arising from dated population estimates and motivates hierarchical modeling. 
Section 4 defines several multilevel model specifications, fitted to answer the 
main questions of interest using the voter and population data, and Section 5 
reviews the results. Lastly, Section 6 introduces limitations of the analysis 
and summarizes relevant findings.

# Background Information
Experimental data is often collected with an inherent nesting which can violate
traditional modeling assumptions, like i.i.d. errors, and lead to poor uncertainty
estimation if ignored. A hierarchical model is a statistical inference tool that
addresses this concern by replicating the natural nesting structure of observed
data. In multilevel or hierarchical modeling, model parameters are defined at 
different group membership levels and permitted to vary across groups. This can 
account for heterogeneity and improve uncertainty estimation attributed to 
group membership. Voter registration and population estimates are generally
aggregated by geography (most naturally by county) during collection. In politics,
it's generally known that individuals display different tendencies depending on 
geography (urban vs. rural). This structure lends itself well to hierarchical 
modeling, allowing parameters to vary by geography for more accurate effect 
estimates.

Hierarchical models can be estimated using Bayesian or Frequentist assumptions 
and I focus on Bayesian methods. In Bayesian estimation, parameters are treated 
as random quantities and derived from posterior distributions using Bayes rule.
Posteriors provide more direct uncertainty quantification than Frequentist methods
through credible regions (CR), which avoid caveats of traditional confidence intervals.
However, this interpretability can come with increased computational costs, as 
Bayesian inference relies on expensive sampling methods compared to likelihood 
based optimization under Frequentist methods. This analysis utilizes conjugate 
priors to avoid excessive computational costs. 

# Data Overview
To investigate the main questions of interest data from the 
[2010 U.S. Census](https://www.census.gov/data.html) was enhanced with North 
Carolina [voter registration](https://vt.ncsbe.gov/) records from the 2016 
Presidential election. To combine datasets, demographic field values were
standardized, as the coding structure varies slightly between State and Federal 
agencies. In total, there were 6,858 county level observations with unknown gender
specification (~15%), lacking a matching population estimate from the Census and
these records were dropped. Irrelevant registration fields denoting precinct 
location were also removed. Metadata information for the combined dataset and a 
sample observation, can be viewed in Table 1.

```{r, show-metadata, include=TRUE, fig.height=3.3}
## ignore U issue and drop out
model_df = voter_stats %>% 
  inner_join(census)

# compute features
model_df$Age = as.factor(model_df$Age)
model_df$Gender = as.factor(model_df$Gender)
model_df$Hispanic = as.factor(model_df$Hispanic)
model_df$Race = as.factor(model_df$Race)
model_df$PartyCd = as.factor(model_df$party_cd)
model_df = model_df %>% 
  dplyr::select(-party_cd)

model_df = model_df %>% 
  filter(Freq > 0)

set.seed(7777)
options(scipen=999)
options(digits = 3)
sample = model_df %>% slice_sample(n=1)

tbl_df = data.frame(
    Column.Names = colnames(model_df),
    Column.Description = c(
      "County in North Carolina",
      "Age Demographic Category",
      "Gender Demographic Category",
      "Demographic Indicator of Hispanic Origin",
      "Race Demographic Category",
      "Number of Registered Voters in Specified Demographics",
      "Total Population Count for Specified Demographics",
      "Total County Population",
      "Political Party Affiliation"
    ),
    Sample = t(sample)
)

ggtexttable(tbl_df, rows=NULL, cols = c("Field Name", "Description", "Sample"),
                  theme=ttheme("classic", base_size = 10, padding=unit(c(5,5), "mm"))) %>%
  table_cell_font(row = 2:(nrow(tbl_df) + 1), column = 1, face = "bold", size = 8) %>%
  table_cell_font(row = 2:(nrow(tbl_df) + 1), column = 2, face = "italic", size = 8) %>%
  table_cell_font(row = 2:(nrow(tbl_df) + 1), column = 3, face = "italic", size = 8) %>%
  tab_add_title(text = "Table 1: Metadata Information", size = 10, face = "plain",
                padding=unit(c(1,0), "mm"))
```

## Population Migration
The 2010 Census is assumed to represent the voter population during the 2016 
election, however, **16.3%** of all observations have more registered voters than
the demographic population estimates from the Census. Are we observing potential
voter fraud or is Census information from six years prior too dated to reflect 
accurate population metrics at the time of the election? To understand the scope 
of this issue, the difference between total registered voters and Census estimates
were computed and aggregated by county. Figure 1 shows summaries for geographies
with more than five observations for ease of viewing. Coincidentally, **16%** of
counties have median population difference greater than **100 individuals**, 
however, **70%** of counties have median difference less than **50** and **35%** 
have medians less than **10**. The majority of moderately small differences assuages
some concerns of major population shifts over the six year period. Population 
estimates for the "invalid" observations are set to the sum of registered voters,
reflecting a 100% registration rate (a potential source of error), but could also
be inflated with a correction factor learned from other observations.

\newpage

```{r, bad-data-boxplot, include=TRUE, fig.height=4.25, fig.cap="Registration Differences by County", fig.align='left'}
## get observations meeting the criteria
sample = model_df %>%
  group_by(Geography, Age, Gender, Hispanic, Race, Freq) %>%
  summarise(party_affiliation_sum = sum(VoterFreq)) %>%
  inner_join(model_df) %>%
  filter(party_affiliation_sum > Freq) %>%
  mutate(diff = party_affiliation_sum - Freq)

## get median metrics by county for above paragraph
# sample %>%
#   group_by(Geography) %>%
#   summarise(med_diff = median(diff)) %>%
#   filter(med_diff > 100) %>%
#   count()

## remove counties with less than 5 observation to make plot easier to read
sample = sample %>% 
  inner_join(sample %>% group_by(Geography) %>% 
               count() %>% filter(n > 5), keep = FALSE) %>%
  dplyr::select(-n)

ggplot(sample, aes(x = reorder(Geography, log(diff), median), y=log(diff))) +
    geom_boxplot(outlier.size = 0.1) +
  ggtitle("Registration Differences by County") + ylab("Population Difference") +
  xlab("County") +
  theme_minimal() +
  geom_hline(yintercept = log(100), linetype="solid", color="darkred", size=0.5) +
  geom_hline(yintercept = log(50), linetype="solid", color="gold", size=0.5) +
  geom_hline(yintercept = log(10), linetype="solid", color="darkgreen", size=0.5) +
  theme(legend.position="none",
        plot.title = element_text(hjust = 0.5),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.text = element_text(size = 10),
        axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  scale_y_continuous(breaks = log(c(1, 10, 50, 100, 500, 5000)),
                   labels = c(1, 10, 50, 100, 500, 5000))
```

To minimize error, 30 counties were randomly selected using sampling weights 
inversely proportional to the percentage of faulty observations 
($\text{total registered voters} > \text{demographic population}$). This framework
can be easily extended to a bootstrap resampling procedure for different county 
combinations to reduce variance. By using sampling weights I hope to reduce estimate
variation by steering the model towards more accurate data at the expense of added 
bias. An additional benefit of sub-sampling is a reduction in computation time for
MCMC inference.

```{r, sample-counties-modeling-df}
## use 1-bad_data_percent as sampling weight for county selection
weight_df = model_df %>% 
                 group_by(Geography) %>% 
                 count() %>% 
                 left_join(sample %>% 
                             group_by(Geography) %>% 
                             count(), by="Geography") %>% 
                 mutate(n.y = 
                          case_when(is.na(n.y) ~ as.integer(0), TRUE ~ n.y)) %>%
                 mutate(bad_data_percent = n.y/n.x)

weights = 1 - weight_df$bad_data_percent
counties = weight_df$Geography

## sample 
set.seed(1235)
samp = sample(counties, 30, replace = FALSE, prob = weights)

### adjust the invalid values (Freq)
## for "invalid" voter_freq, set Freq = sum of party affiliations 
## also compute new freq denominator based on given affiliation
model_df = model_df  %>%
  group_by(Geography, Age, Gender, Hispanic, Race) %>%
  summarise(party_affiliation_sum = sum(VoterFreq)) %>%
  inner_join(model_df) %>% 
  ## update Freq for Invalid Values
  mutate(Freq = case_when(
    # VoterFreq >= Freq ~ party_affiliation_sum,
    party_affiliation_sum > Freq ~ party_affiliation_sum,
    TRUE ~ Freq)) %>%
  ## compute new freq denominator. Partition the available voters to a party and add to the VoterFreq
  mutate(Affil_Freq =
           round((VoterFreq/party_affiliation_sum) * (Freq-party_affiliation_sum)) + VoterFreq)

## filter to relevant fields
test_df = model_df %>% 
  filter(!Geography %in% samp)
model_df = model_df %>% 
  filter(Geography %in% samp)
```

```{r, verify-partition-strategy}
## verify the imputed sums match the true freqs or at least are within 1
# model_df %>% 
#   ungroup() %>% 
#   group_by(Geography, Age, Gender, Hispanic, Race, Freq) %>%
#   summarize(val = sum(Affil_Freq))
# saveRDS(model_df, file="model_df.RDS")
```

## Motivating a Multilevel Model 
Voter data and population estimates are naturally grouped by geography, suggesting
a multilevel model using county. We are interested in understanding how covariates, 
like age and political affiliation, influence registration rates. A model, without
any hierarchical components, can be formatted as a binomial regression, where 
registered voters represent the number of "successes" from a set of "trials" 
reflected as population estimates. To evaluate modeling decisions, like where to
apply random effects, an exploratory data analysis was conducted. Figure 2 displays 
facet plots for different binomial regressions for two demographic categories and 
color coded by county. (A) fits regressions by county/age and displays substantially
different trends across/within facets, suggesting a random effect. While (B) fits
regressions by county/race and displays much lower facet variability, suggesting 
a fixed effect. Additional combinations can by found in the Appendix. Continuous
covariates, like total county population, hindered posterior mixing and were 
excluded.

Under the current specification it's impossible to determine the effect of political 
affiliation on voter registration, as the Census doesn't collect it with population
estimates and it needs to be imputed. As an initial estimate, political affiliation
can be assigned to unregistered voters from the observed party distribution of 
registered voters for each demographic group.

```{r, motivate-the-model, include=TRUE, fig.cap="Voter Registration Behavior for (A) Age Category and (B) Race", fig.height=13, fig.width=10}
alpha = 0.05

## age
p1 = ggplot(data=model_df,
# p1 = ggplot(data=model_df %>% filter(Geography %in% c("ALAMANCE", "COLUMBUS", "LEE", "YADKIN", "EDGECOMBE")),
       aes(x=Affil_Freq, y=VoterFreq/Affil_Freq, col=Geography,
           group=interaction(Geography, Age))) +
  geom_point(size = 1.2, alpha=alpha) + 
  theme_minimal() +
  # guides(color=FALSE) +
  guides(linetype = guide_legend(override.aes = list(color = "#000000"))) +
  scale_linetype_manual(values=c(1,2,3,4)) +
  theme(plot.title = element_text(hjust = 0.5),
          plot.subtitle = element_text(hjust = 0.5), 
          legend.box="vertical",
          legend.margin=margin(),
          legend.position="none",
          panel.border = element_rect(colour = "black", fill=NA, size=1)) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  coord_cartesian(ylim = c(0.25,1)) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se=FALSE,
            size=.4, fullrange=TRUE) +
  # labs(subtitle = "Age") + 
  ylab("Registration Probability") + xlab("Demographic Population")

p1 = p1 + facet_wrap(~Age) + theme(strip.text.x = element_text(size = 14, face = "bold.italic"))

## by race
p2 = ggplot(data=model_df,
# p2 = ggplot(data=model_df %>% filter(Geography %in% c("ALAMANCE", "COLUMBUS", "LEE", "YADKIN", "EDGECOMBE")),
       aes(x=Affil_Freq, y=VoterFreq/Affil_Freq, col=Geography,
           group=interaction(Geography, Race))) +
  geom_point(size = 1.2, alpha=alpha) + 
  theme_minimal() +
  # guides(color=FALSE) +
  theme(plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5),
          panel.border = element_rect(colour = "black", fill=NA, size=1),
          # axis.title.y=element_blank(),
          legend.position="none") +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se=FALSE,
            size=.4, fullrange=TRUE) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  coord_cartesian(ylim = c(0,1)) +
  # labs(subtitle = "Race") + 
  ylab("Registration Probability") + xlab("Demographic Population")

p2 = p2 + facet_wrap(~Race) + 
  theme(strip.text.x = element_text(size = 11, face = "bold.italic"))

plot = ggarrange(p1, p2,ncol=1, nrow=2, common.legend = FALSE, labels="AUTO")
annotate_figure(plot, top = text_grob(
  "Voter Registration Probability by Demographic Segmentation",
  face = "bold", size = 15))
```

\newpage

# Multilevel Models

## Model Specifications
The modeling framework can now be specified as follows. Let 
$\left(y_{i}, n_{i}, p_{i}\right)$ denote the number of voter registrations, 
demographic population and registration probability respectively for observation
$i$. $y_{i}$ is assumed to be distributed as a binomial random variable.
$$y_{i} \sim Binomial\left(n_{i}, \ p_{i}\right)$$
Individuals can only register to vote once, but binomial models assume independent
sampling with replacement. This independence assumption seems reasonable, as the
registration probability of any one individual is most likely independent of any
other individual decision (more on this later). Additionally, $\sim 70\%$ of 
demographic categories have populations $n_{i} \geq 30$ which are sufficiently 
large. One might consider a hypergeometric model for more realism, but this would
induce a dependence between $y_{i}$'s which may be unwarranted. Under the binomial
model, several multilevel structures, with varying complexity, were evaluated and
Table 2 displays specifications for each.

```{r, random-effect structure, include=TRUE, fig.height=1.5}
tbl_df = data.frame(
    Fixed.Effects = c("Gender, Hispanic, Race, PartyCd, Age", 
                      "Hispanic, Race, Age", "Gender, Hispanic, Race"),
    Random.Intercept = c("Geography", "PartyCD", "PartyCD"),
    Random.Slope = c("", "Gender", "Age")
)

ggtexttable(tbl_df, rows=c("Model I ", "Model II ", "Model III "), 
            cols = c("Fixed Effect Fields", "Random Intercept Fields", 
                     "Random Slope Fields"),
                  theme=ttheme("classic", base_size = 9, padding=unit(c(5,5), "mm"))) %>%
  tab_add_title(text = "Table 2: Random Effect Structures", size = 9, face = "plain",
                padding=unit(c(1,0), "mm"))
```

### Model I
Let $\mu$ denote a global intercept corresponding to a baseline demographic category 
with the following values: 'Female', 'Hispanic', 'AmericanIndianOrAlaskaNativeAlone',
'DEM' and '18-25'. Let $\theta_{j}$ denote a **county** random effect intercept 
for observations, $i$, in county $j$, $X_{i}$ a vector of demographic indicator
variables corresponding to Fixed Effect Fields in Table 2 and $\beta$ the 
corresponding fixed effect estimates.
$$Logit(p_{ij})) = \mu + \theta_{j} + X_{i}\beta$$
_Prior Specifications_
$$\mu \sim N\left(0,1\right), \ \beta \sim N\left(0, 1\right), \ \theta_{j} \sim N\left(0, \sigma\right)$$
$$\sigma \sim HalfCauchy\left(0, \frac{1}{2}\right)$$

```{r, fit-model-1}
m1 = brm(data = model_df, family = "binomial",
      VoterFreq | trials(Freq) ~ 1 + Gender + Hispanic + Race + PartyCd + Age + (1 | Geography),
      prior = c(prior(normal(0, 1), class = "Intercept"),
                prior(normal(0, 1), class = "b"),  ## class b denotes population (fixed) effects
                prior(cauchy(0, 0.5), class = "sd")  ## group effects
                ),
      file = "models/m1_imputation.rds",
      iter = 2500, 
      warmup = 500,
      chains = 4)
```

### Model II
In accordance with Table 2, let $\mu$ denote a global intercept corresponding to
a baseline demographic category with the following values: 'Hispanic',
'AmericanIndianOrAlaskaNativeAlone' and '18-25'. Let $\Omega_{p}$ denote the 
**party affiliation** random effect for party $p$, let $g_{ipk}$ denote the 
**gender** category, $k$, for observation $i$ in political party $p$ and 
$\Gamma_{pk}$ the random effect. Finally, $X_{i}$ and $\beta$ have identical
interpretations to what was described for Model I.

$$Logit(p_{ipk})) = \mu +  \Omega_{p} + g_{ipk}\Gamma_{pk} + X_{i}\beta$$
_Prior Specifications_
$$\Omega_{p} \sim N\left(0, \sigma\right), \ \Gamma_{pk} \sim N\left(0, \gamma\right), \ \sigma,\gamma \sim HalfCauchy\left(0, \frac{1}{2}\right)$$
$$\mu \sim N\left(0,1\right), \ \beta \sim N\left(0, 1\right)$$

```{r, fit-model-2}
m2 = brm(data = model_df, family = "binomial",
      VoterFreq | trials(Affil_Freq) ~ 1 + Hispanic + Race + Age + (1 + Gender | PartyCd),
      prior = c(prior(normal(0, 1), class = "Intercept"),
                prior(normal(0, 1), class = "b"),  ## class b denotes population (fixed) effects
                prior(cauchy(0, 0.5), class = "sd")  ## group effects
                ),
      file = "models/q3.rds",
      iter = 2500,
      warmup = 500,
      chains = 4)
```

### Model III
In accordance with Table 2, let $\mu$ denote a global intercept corresponding to
a baseline demographic category with the following values: 'Female', 'Hispanic' 
and 'AmericanIndianOrAlaskaNativeAlone'. Let $\Omega_{p}$ denote the 
**party affiliation** random effect for party $p$, let $a_{ipk}$ denote the 
**age** category, $k$ for observation $i$ in political party $p$ and $\alpha_{pk}$
the random effect slope. Finally, $X_{i}$ and $\beta$ have identical
interpretations to what was described for Model I.

$$Logit(p_{ipk})) = \mu +  \Omega_{p} + a_{ipk}\alpha_{pk} + X_{i}\beta$$
_Prior Specifications_
$$\Omega_{p} \sim N\left(0, \omega\right), \ \alpha_{pk} \sim N\left(0, \tau\right), \ \omega,\tau \sim HalfCauchy\left(0, \frac{1}{2}\right)$$
$$\mu \sim N\left(0,1\right), \ \beta \sim N\left(0, 1\right)$$

```{r, fit-model-3}
m3 = brm(data = model_df, family = "binomial",
      VoterFreq | trials(Affil_Freq) ~ 1 + Gender + Hispanic + Race + (1 + Age | PartyCd),
      prior = c(prior(normal(0, 1), class = "Intercept"),
                prior(normal(0, 1), class = "b"),  ## class b denotes population (fixed) effects
                prior(cauchy(0, 0.5), class = "sd")  ## group effects
                ),
      file = "models/q4.rds",
      iter = 2500,
      warmup = 500,
      chains = 4)
```

# Results
MCMC diagnostics, like trace plots, can be viewed in the Appendix for each model.
The main questions of interest concern demographic factors influencing registration
probabilities and are now discussed.

## _How did different demographic subgroups register to vote?_
The fixed effect estimates from each model are plotted in Figure 3 with 95% CR. 
Note, not all models include identical fixed effects, but the overlapping
estimates tend to display more shrinkage with increased model complexity. 
Significance is interpreted as CR not encompassing 0. Starting from the top of 
Figure 3, all Race indicators have significant impact on registration rate while 
party affiliation displays no significant effect. Hispanic & Gender estimates are
significant and Older individuals are also more likely to register, but this can
be attributed to having more opportunities/elections to do so. 

```{r, demographic-subgroup-analysis, include=TRUE, fig.align='left', fig.height=4, fig.cap="Fixed Effect Estimates From Each Model", fig.height=3}
model_names = c("Model I", "Model II", "Model III")
models = list(m1, m2, m3)
num_models = length(model_names)
tst = c()
for(i in 1:num_models){
  tst = rbind(tst, compute_fixed_effect_intervals(models[[i]], model_names[i]))
}

ggplot(tst, aes(x=Estimate, y=parameter, xmin = Q2.5, xmax = Q97.5, color=Model)) +
  geom_pointinterval(alpha = 0.5, shape=1) +
  theme_minimal() +
  # geom_errorbar(aes(xmin=Q2.5, xmax=Q97.5, color=model), width=.1) +
  ggtitle("Demographic Effect Estimates") +
  xlab("Change in Log Odds") + 
  theme(plot.title = element_text(hjust = 0.5),
        legend.position="bottom",
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.y=element_blank()) + 
    geom_vline(xintercept =0, linetype="dashed", color="darkred", size=0.5)
```

## _Did the overall odds of registering differ by county in 2016?_
Only 30 counties, viewable in the Appendix, are included in estimation. The 
random intercepts from Model I, with 95% CR are displayed in Figure 4. Tyrrell, 
the only county without any "invalid" observations, has the lowest registration 
effect, while **43%** of counties display no effect.

```{r, present-county-intercept, include=TRUE, fig.cap="County Level Intercept Estimates from Model I", fig.height=4}
m1 %>%
  spread_draws(b_Intercept, r_Geography[Geography,]) %>%
  # median_qi(county_mean = b_Intercept + r_Geography) %>%
  median_qi(county_mean = r_Geography) %>%
  # ggplot(aes(y = Geography, x = county_mean, xmin = .lower, xmax = .upper)) +
  ggplot(aes(y = reorder(Geography, county_mean, mean), x = county_mean, 
             xmin = .lower, xmax = .upper)) +
  geom_pointinterval(alpha = 0.5, shape=1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position="bottom",
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.y=element_blank()) +
  geom_vline(xintercept =0, linetype="dashed", color="darkred", size=0.5) +
  ggtitle("County Effect on Voter Registration") +
  xlab("Change in Log Odds")
```

## _How do registration rates differ by gender for each party?_
Using Model II we can look at the gender effect within each political party from
random slope estimates and assess the relative change in log odds from the baseline
(Female). Figure 5 shows 95% CRs and point estimates. Males across all political 
parties are less likely to register than corresponding females and republican 
males register at the highest rates.

```{r, include=TRUE, fig.height=1.75, fig.cap="Random Slope Estimates (Model II) for Gender across Political Party", fig.align='left'}
m2 %>%
  spread_draws(r_PartyCd[PartyCd, Gender]) %>%
  median_qi(est = r_PartyCd) %>%
  filter(Gender != "Intercept") %>%
  ggplot(aes(y = paste(Gender, PartyCd), x = est, xmin = .lower, xmax = .upper)) +
  geom_pointinterval(alpha = 0.5, shape=1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position="bottom",
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.y=element_blank()) +
  ggtitle("Gender Effect on Registration Rates by Political Party") +
  xlab("Change in Log Odds")
```

## _Registration differences by age group for each party?_
Random slope estimates from Model III are the registration effects for different 
age groups relative to a baseline (18-25). Figure 6 shows 95% CRs and point
estimates for different political parties and age groups. Across age categories 
republicans are more likely to register than other political parties and registration
rates tend to increase with age. 

```{r, include=TRUE, fig.height=2.2, fig.cap="Random Slope Estimates for Age across Political Party", fig.align='left'}
m3 %>%
  spread_draws(r_PartyCd[PartyCd, Age]) %>%
  median_qi(est = r_PartyCd) %>%
  filter(Age != "Intercept") %>%
  ggplot(aes(y = paste(Age, PartyCd), x = est, xmin = .lower, xmax = .upper)) +
  geom_pointinterval(alpha = 0.5, shape=1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position="bottom",
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.y=element_blank()) +
  ggtitle("Age Effects on Registration Rates by Political Party") +
  xlab("Change in Log Odds")
```

## Predictive Accuracy
Comparing predicted voters to actual registrations using the out-of-sample data 
can be used to assess model validity. Figure 7 displays predictions for each 
demographic group within one county and dashed lines denote average error. 
Surprisingly, Model I has the best predictive performance, with average error of
roughly 10 individuals, but median error less than one. 

```{r, predictive-accuracy, include=TRUE, fig.height=2.8, fig.cap="Predictive Accuracy across Demographic Groups"}
## select county from test set at random
set.seed(777)
cnty = (test_df %>% ungroup() %>% distinct(Geography) %>% sample_n(1))$Geography

pred_df = test_df %>% ungroup()%>% dplyr::filter(Geography == cnty) %>%
  distinct(Geography, Race, Hispanic, Gender, Age) %>%
  dplyr::inner_join(test_df) %>%
  dplyr::select(Geography, Race, Hispanic, Gender, Age, Freq, VoterFreq, PartyCd, Affil_Freq)

results = return_pred_df(pred_df, m1, m2, m3)

## display results
ggplot(results, aes(x=index, y=abs_diff, color = Model)) +
  geom_point(alpha = 0.7, shape=1) +
  theme_minimal() +
  ggtitle("Predictive Accuracy for One County") +
  xlab("Demographic Group") + ylab("Error (Actual - Predicted)") +
  theme(legend.position="bottom",
        plot.title = element_text(hjust = 0.5),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.text.x=element_blank(),
         axis.ticks.x=element_blank()) +
  geom_hline(data= results %>% 
                    group_by(Model) %>% 
                    summarise(model_mean = mean(abs_diff)), 
             aes(yintercept = model_mean,col=Model), linetype="dashed")
```

Table 3 displays the overall predictive performance for the full out-of-sample 
set. The average absolute error denotes the difference, in number of individuals, 
between model predictions and observed number of registered voters. The median
error is substantial less than the average and indicates some predictions are 
significantly wrong.

```{r, total-pred-accuracy, include=TRUE, fig.height=1.4}
## overall predictions
if(file.exists("./data/report_df/out_of_samp.RDS")){
  out_of_samp = readRDS("./data/report_df/out_of_samp.RDS")
}else{
  out_of_samp = return_pred_df(test_df, m1, m2, m3)
  saveRDS(out_of_samp, file="./data/report_df/out_of_samp.RDS")
}

## these are both are to discern bc of outliers
## boxplot
# ggplot(out_of_samp, aes(x=Model, y=(abs_diff))) + 
#   geom_boxplot()

## diff residual plot
# ggplot(out_of_samp, aes(abs_diff, color=Model)) + 
#   geom_density()
##
## table 1: error summaries
tbl_df = out_of_samp %>% 
  group_by(Model) %>% 
  summarise(
    avg_error = mean(abs(abs_diff)),
    median_error = median(abs(abs_diff)),
    ) %>%
  dplyr::select(-Model)

ggtexttable(round(tbl_df, 2), rows=c("Model I ", "Model II ", "Model III "), 
        cols = c("Avg. Absolute Error", "Median Absolute Error"),
                  theme=ttheme("classic", base_size = 9, padding=unit(c(5,5), "mm"))) %>%
  tab_add_title(text = "Table 3: Prediction Summaries", size = 9, face = "plain",
                padding=unit(c(1,0), "mm"))
```

Table 4 shows the 95% credible region summaries for each model prediction. All
models display substantially worse performance on the out-of-sample test set
than the coverage level. Model I predictions have dramatically wider intervals
than other models.

```{r, prediction-summary-table, include=TRUE, fig.height=1.4}
## table 2: CI width summaries
tbl_df = out_of_samp %>% 
  group_by(Model) %>% 
  summarise(
    ## Confidence Interval Statistics
    percent_CI_coverage = sum(within_region)/(nrow(out_of_samp)/3),
    avg_CI_width = mean((Q97.5-Q2.5))) %>%
  dplyr::select(-Model)

ggtexttable(round(tbl_df, 2), rows=c("Model I ", "Model II ", "Model III "), 
        cols = c("Confidence Interval Coverage", "Avg. CI Width"),
                  theme=ttheme("classic", base_size = 9, padding=unit(c(5,5), "mm"))) %>%
  tab_add_title(text = "Table 4: Confidence Interval Summaries", size = 9, face = "plain",
                padding=unit(c(1,0), "mm"))
```

# Limitations & Conclusion
Historical voting records and population estimates were used to evaluate 
demographic differences in registration tendencies. Three Bayesian multilevel
models were created to address specific questions of interest using different
effect structures. The full dataset was sub-sampled to reduce computation time, 
but may lead to higher variance estimates. Preliminary results suggest significant
differences in registration tendencies across demographic categories in North
Carolina.

There are several limitations to this analysis. First, population estimates in 
2016 are approximated from the 2010 Census. This may introduce unaccounted for
variability if significant population changes occurred over the six year period. 
Multiple instances of observations with more registered voters than demographic
population estimates, which should be impossible, may reflect this. To minimize
potential variability a weighted sub-sample was drawn for inference. This addresses
detectable population differences, but does not account for the possibility that
all population estimates are different over the time period. In the future, one
could/should look to include 2020 Census estimates, when they become available in
2023, to impute more realistic population measures that combine Census estimates
from both years. The sub-sample also reduces the size of the dataset, adding 
variability, but required to reduce MCMC sampling time which can take over 12 
hours on a laptop with the reduced dataset. One could leverage the entire dataset
with a bootstrap resampling procedure and run multiple models in parallel to reduce
variance concerns. An additional limitation is the latent political affiliation
of unregistered voters, as the Census does not collect this information. These 
totals were imputed based on the party affiliations of registered voters as a 
rough approximation, but implies strong assumptions about how individuals register
and may be better to adopt another modeling approach entirely. One alternative 
is to treat registration affiliation (democrats, republicans, libertarians, 
unaffiliated, not registered) as a multinomial draw from the total population and
use registered individuals purely as response variables instead of imputing true
affiliations. Lastly, overdisperion is almost always a problem in binomial regression
models, as there is no independent variance term. If overdispersion  is present,
parameter estimates will be overconfident. Due to time constraints, overdispersion
was neglected, but one could apply an uncertainty adjustment to estimates to account
for this possibility. 

\newpage

# Appendix

**Additional Covariate Plots**  
```{r, additional-covariate-plots, include=TRUE}
## gender: consistent trends
ggplot(data=model_df,
       aes(x=Affil_Freq, y=VoterFreq/Affil_Freq, col=Geography, group=interaction(Geography, Gender))) +
  geom_point(size = 1.2, alpha=alpha) + 
  theme_minimal() +
  # guides(color=FALSE) +
  theme(plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5),
          panel.border = element_rect(colour = "black", fill=NA, size=1),
          # axis.title.y=element_blank(),
          legend.position="none") +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se=FALSE,
            size=.4, fullrange=TRUE) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  coord_cartesian(ylim = c(0,1)) +
  labs(subtitle = "Gender") +
  ylab("Registration Probability") + xlab("Demographic Population") + 
  facet_wrap(~Gender) + theme(strip.text.x = element_text(size = 12, face = "bold.italic"))

## partycd: similar trends
ggplot(data=model_df,
       aes(x=Affil_Freq, y=VoterFreq/Affil_Freq, col=Geography, group=interaction(Geography, PartyCd))) +
  geom_point(size = 1.2, alpha=alpha) + 
  theme_minimal() +
  # guides(color=FALSE) +
  theme(plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5),
          panel.border = element_rect(colour = "black", fill=NA, size=1),
          # axis.title.y=element_blank(),
          legend.position="none") +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se=FALSE,
            size=.4, fullrange=TRUE) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  coord_cartesian(ylim = c(0,1)) +
  labs(subtitle = "Party Affiliation") +
  ylab("Registration Probability") + xlab("Demographic Population") + 
  facet_wrap(~PartyCd) + theme(strip.text.x = element_text(size = 12, face = "bold.italic"))

## hispanic: similar trends
ggplot(data=model_df,
       aes(x=Affil_Freq, y=VoterFreq/Affil_Freq, col=Geography, group=interaction(Geography, Hispanic))) +
  geom_point(size = 1.2, alpha=alpha) + 
  theme_minimal() +
  # guides(color=FALSE) +
  theme(plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5),
          panel.border = element_rect(colour = "black", fill=NA, size=1),
          # axis.title.y=element_blank(),
          legend.position="none") +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se=FALSE,
            size=.4, fullrange=TRUE) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  coord_cartesian(ylim = c(0,1)) +
  labs(subtitle = "Hispanic") +
  ylab("Registration Probability") + xlab("Demographic Population") + 
  facet_wrap(~Hispanic) + theme(strip.text.x = element_text(size = 12, face = "bold.italic"))

# ggplot(data=model_df %>% filter(Geography %in% c("JACKSON", "COLUMBUS", "LEE")),
#        aes(x=Freq, y=VoterFreq, col=Geography, group=interaction(Geography, Gender))) +
#   geom_point(size = 1.2, alpha=.9) + 
#   theme_minimal() +
#     theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
#   geom_smooth(method = lm, se=FALSE, size=.5, alpha  = .5) +
#   theme(panel.border = element_rect(colour = "black", fill=NA, size=1),
#         legend.position = "none") +
#   labs(subtitle = "Color by Geography & Fit by Gender") + 
#   ylab("Registered Voters") + xlab("Total Demographic Population")
# 
# ggplot(data=model_df %>% filter(Geography %in% c("JACKSON", "COLUMBUS", "LEE")),
#        aes(x=Freq, y=VoterFreq, col=Geography, group=interaction(Geography, Hispanic))) +
#   geom_point(size = 1.2, alpha=.9) + 
#   theme_minimal() +
#     theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
#   geom_smooth(method = lm, se=FALSE, size=.5, alpha  = .5) +
#   theme(panel.border = element_rect(colour = "black", fill=NA, size=1), legend.position = "none") +
#   labs(subtitle = "Color by Geography & Fit by Hispanic") + 
#   ylab("Registered Voters") + xlab("Total Demographic Population")
# 
# ggplot(data=model_df %>% filter(Geography %in% c("JACKSON", "COLUMBUS", "LEE")),
#        aes(x=Freq, y=VoterFreq, col=Geography, group=interaction(Geography, PartyCd))) +
#   geom_point(size = 1.2, alpha=.9) + 
#   theme_minimal() +
#     theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
#   geom_smooth(method = lm, se=FALSE, size=.5, alpha  = .5) +
#   theme(panel.border = element_rect(colour = "black", fill=NA, size=1), legend.position = "none") +
#   labs(subtitle = "Color by Geography & Fit by Political Party") + 
#   ylab("Registered Voters") + xlab("Total Demographic Population")

### the original linear regression plots...we don't want to use these
# ggplot(data=model_df %>% filter(Geography %in% c("WAKE", "MECKLENBURG", "BUNCOMBE")),
# alpha = 0.05
# p1 = ggplot(data=model_df %>% filter(Geography %in% c("JACKSON", "COLUMBUS", "LEE")),
#        aes(x=Freq, y=VoterFreq, col=Geography, group=interaction(Geography, Age))) +
#   geom_point(size = 1.2, alpha=alpha) + 
#   theme_minimal() +
#     theme(plot.title = element_text(hjust = 0.5),
#           plot.subtitle = element_text(hjust = 0.5),
#           axis.title.x=element_blank(),
#           legend.position="bottom",
#           panel.border = element_rect(colour = "black", fill=NA, size=1)) +
#   geom_smooth(method = lm, se=FALSE, size=.6) +
#   # theme(legend.position="bottom", panel.border = element_rect(colour = "black", fill=NA, size=1)) +
#   labs(subtitle = "Age (Linear)") + 
#   ylab("Registered Voters") + xlab("Total Demographic Population")
# 
# ## by race
# p2 = ggplot(data=model_df %>% filter(Geography %in% c("JACKSON", "COLUMBUS", "LEE")),
#        aes(x=Freq, y=VoterFreq, col=Geography, group=interaction(Geography, Race))) +
#   geom_point(size = 1.2, alpha=alpha) + 
#   theme_minimal() +
#     theme(plot.title = element_text(hjust = 0.5),
#           axis.title.y=element_blank(),
#           axis.title.x=element_blank(),
#           plot.subtitle = element_text(hjust = 0.5)) +
#   geom_smooth(method = lm, se=FALSE, size=.6) +
#   theme(panel.border = element_rect(colour = "black", fill=NA, size=1), 
#         legend.position = "none") +
#   labs(subtitle = "Race (Linear)") + 
#   ylab("Registered Voters") + xlab("Total Demographic Population")
# 
# plot = ggarrange(p1, p2, ncol=2, nrow=1, common.legend = TRUE, legend="top", 
#                  widths = c(1.05,0.95))
# annotate_figure(plot, top = text_grob("Voter Registration vs. Demographic Population"
#                                       , face = "bold", size = 13))
```

**Trace Plots**  

```{r, m1-trace-plots, include=TRUE}
m1df = ggs(m1)
# get the same plots without bayesplot...have to filter out the warmup!
m1df$Chain = factor(m1df$Chain)
# caterpillar trace plots
## only pick some parameters for plotting
ggplot(filter(m1df, Parameter %in% c("b_Age66P", "b_GenderMale", "b_HispanicNotHispanic")),
       aes(x   = Iteration,
           y   = value,
           col = as.factor(Chain)))+
  theme_minimal() +
  geom_line() +
  geom_vline(xintercept = 500) + ## add vertical line at the default warm-up value 1000
  facet_grid(Parameter ~ . , scale  = 'free_y', switch = 'y') +
  labs(title = "Model I: Trace Plots", col   = "Chains")
```

```{r, m2-trace-plots, include=TRUE}
m2df = ggs(m2)
# get the same plots without bayesplot...have to filter out the warmup!
m2df$Chain = factor(m2df$Chain)
# caterpillar trace plots
## only pick some parameters for plotting
ggplot(filter(m2df, Parameter %in% c("r_PartyCd[LIB,GenderMale]", "r_PartyCd[REP,GenderMale]", "r_PartyCd[DEM,GenderMale]", "r_PartyCd[UNA,Intercept]")),
       aes(x   = Iteration,
           y   = value,
           col = as.factor(Chain)))+
  theme_minimal() +
  geom_line() +
  geom_vline(xintercept = 500) + ## add vertical line at the default warm-up value 1000
  facet_grid(Parameter ~ . , scale  = 'free_y', switch = 'y') +
  labs(title = "Model II: Trace Plots", col   = "Chains")
```

```{r, m3-trace-plots, include=TRUE}
m3df = ggs(m3)
# get the same plots without bayesplot...have to filter out the warmup!
m3df$Chain = factor(m3df$Chain)
# caterpillar trace plots
## only pick some parameters for plotting
ggplot(filter(m3df, Parameter %in% c("r_PartyCd[DEM,Age26M40]", "r_PartyCd[REP,Age41M65]", "r_PartyCd[LIB,Age66P]", "r_PartyCd[UNA,Age66P]")),
       aes(x   = Iteration,
           y   = value,
           col = as.factor(Chain)))+
  theme_minimal() +
  geom_line() +
  geom_vline(xintercept = 500) + ## add vertical line at the default warm-up value 1000
  facet_grid(Parameter ~ . , scale  = 'free_y', switch = 'y') +
  labs(title = "Model III: Trace Plots", col   = "Chains")
```


**County Sample List**  
```{r, include=TRUE}
model_df %>% 
  ungroup() %>%
  distinct(Geography) %>%
  pander()
```




